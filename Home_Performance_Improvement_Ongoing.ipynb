{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPcPuA8C6Rn-"
   },
   "outputs": [],
   "source": [
    "#! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tiUF8EliFbe"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rl9EghkTtBcy",
    "outputId": "4e901511-0118-4d73-a186-4caa8e24dc69"
   },
   "outputs": [],
   "source": [
    "import sys ## used for functions that interact strongly with the interpreter (i.e. a program that reads and execute codes)\n",
    "import copy ## to use copying functions\n",
    "import pandas as pd ## library for dataset manipulation\n",
    "import numpy as np ## mathematical function on arrays and matrices\n",
    "import matplotlib.pyplot as plt ## for basic plotting\n",
    "import seaborn as sns ## easier plotting and updated matplotlib library \n",
    "from sklearn.preprocessing import StandardScaler,PowerTransformer ## for standardization on numerical variables\n",
    "from pandas_profiling import ProfileReport ## for a complete pandas DataFrame report\n",
    "import plotly.express as px ## 'plotly.express' for scatter plotting on location data with a location map \n",
    "import statsmodels ## statsmodel module for using statistical models\n",
    "import statsmodels.api as sm ## api module for OLS model from statsmodels, assigned as sm\n",
    "import statsmodels.stats.api as sms ## api module for Gold-Feld Quandt Test from statsmodels.stats, assigned as sms\n",
    "from sklearn.model_selection import train_test_split ## for splitting the dataset into train and test\n",
    "from sklearn.metrics import mean_squared_error,r2_score ## for mse and r-squared\n",
    "from sklearn.neighbors import KNeighborsRegressor ## for KNN-Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor ## for Decision Tree Regressor\n",
    "import scipy.stats as stats ## for probability distribution and statistical functions\n",
    "from scipy.stats import f_oneway,jarque_bera,shapiro ## for assumptions and statistical significance\n",
    "from scipy.stats import norm,randint,skewnorm ## for normal continuous random variables and randomized integer variables\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif ## for variance inflation factor\n",
    "from statsmodels.graphics.gofplots import qqplot ## for plotting q-q plots\n",
    "import statsmodels.tsa.api as smt ## to use model classes and functions for time series analysis\n",
    "from sklearn.model_selection import GridSearchCV ## for random cross-validation\n",
    "from warnings import filterwarnings ## to remove warnings\n",
    "filterwarnings('ignore') ## assigning warnings to 'ignore'\n",
    "pd.set_option('display.max_columns', None) ## to show all columns\n",
    "np.set_printoptions(threshold=sys.maxsize) ## to show the complete list or arrays\n",
    "## will lead to static images of your plot embedded in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2gV3SPZ8Qa9"
   },
   "source": [
    "# Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "id": "tjfYVg8stX6m",
    "outputId": "206998bd-4354-45cb-ac7a-4a76ec9e4a42"
   },
   "outputs": [],
   "source": [
    "home = pd.read_csv('homeperf.csv') ## reading the '.csv' file \n",
    "df = copy.deepcopy(home) ## copying to workstation dataset\n",
    "home ## showing original DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PudyO1G39T7N"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIrpoqh92cEY"
   },
   "source": [
    "## Data Preprocessing (Part-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzarg9fY2Wse"
   },
   "source": [
    "### Features of the Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhXTVMF3t5yQ",
    "outputId": "a126ee74-8feb-45e2-bdae-6ebad6e2d96b"
   },
   "outputs": [],
   "source": [
    "## printing shape of the original DataFrame\n",
    "print(home.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "K2MVUR2tlNpP",
    "outputId": "3133fe54-21ea-4dc6-854b-dd4a082856a4"
   },
   "outputs": [],
   "source": [
    "## descriptive statistics of the original DataFrame\n",
    "home.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeSJKzD7t_2w",
    "outputId": "c0db5d54-b01d-4ec3-d1a9-8d4367413594"
   },
   "outputs": [],
   "source": [
    "## printing information of the original DataFrame\n",
    "print(home.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YayIES_tPqRz",
    "outputId": "4fe84f28-57db-4948-87b9-b006b57d2d94"
   },
   "outputs": [],
   "source": [
    "cat_cols_home = home.select_dtypes(include='object').columns ## selecting categorical columns into a list\n",
    "num_cols_home = home.select_dtypes(include=np.number).columns ## selecting numeric columns into a list\n",
    "print('Categorical:',cat_cols_home) ## printing categorical column names\n",
    "print('\\n') ## for spacing\n",
    "print('Numerical:',num_cols_home) ## printing numerical column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33Q8E6IN2hNH"
   },
   "source": [
    "### Null Value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIzk12KBUeEh",
    "outputId": "bd0924a6-7a14-47ec-9b24-43814dba270c"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZihXO6lY5QS_",
    "outputId": "ccafdf40-0e0b-4933-f9fb-e1511f17aa2e"
   },
   "outputs": [],
   "source": [
    "## using for and if loops to gather null values in percentages for null value count greater than 0\n",
    "for i in df:\n",
    "  if ((df[i].isna().sum()/len(df[i]))*100)>0:\n",
    "    print('Percentage of null values in',i,'is',round(((df[i].isna().sum()/len(df[i]))*100),3),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "yjHz94jNS91r",
    "outputId": "6d113d1e-764f-48e3-a98c-2cac311f9346"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df.isna())\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-D3Ubk82x5N"
   },
   "source": [
    "- More than 10% null values in 'Gas Utility' and 'Year Home Built'. Hence, we drop both the columns.\n",
    "- Only 0.004% or 1 null value in 'Number of Units'. Hence, we drop the null value row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSsC4kDl5Sc1",
    "outputId": "c12f3340-0751-4386-eb83-26d7221806ed"
   },
   "outputs": [],
   "source": [
    "df.drop(['Gas Utility','Year Home Built'],axis=1,inplace=True) ## dropping the extreme null value columns\n",
    "df.dropna(inplace=True) ## dkropping the null value row\n",
    "print(df.shape) ## printing the shape of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Q5fdcngx1Kb",
    "outputId": "2ab337f5-b323-4866-b25b-9984af8b1a5d"
   },
   "outputs": [],
   "source": [
    "## checking for null values again after treatment\n",
    "for i in df:\n",
    "  if ((df[i].isna().sum()/len(df[i]))*100)>0:\n",
    "    print('Percentage of null values in',i,'is',round(((df[i].isna().sum()/len(df[i]))*100),3),'%')\n",
    "  else:\n",
    "    print('No null values in the dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUvuf8IE3QnI"
   },
   "source": [
    "- Checking for null values shows that null values have been treated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJ9QbM0bmRM9"
   },
   "source": [
    "### Fixing Duplicated Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "qFgVR5NTmUvY",
    "outputId": "c277b51c-aabf-46a9-8dc6-48ccfe5b1374"
   },
   "outputs": [],
   "source": [
    "## check for duplicated rows \n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcYy3wpomgNr"
   },
   "source": [
    "- No duplicated values.\n",
    "- If duplicated values made after feature engineering, **ignore**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lt2jE9Q73Yrr"
   },
   "source": [
    "### Feature dType correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnSjlCcMx4ud",
    "outputId": "c90eed7d-2534-43a2-85fc-723d77168e84"
   },
   "outputs": [],
   "source": [
    "## printing dataframe info to check wrongly specified feature dtype\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbBAhFTU3g2E"
   },
   "source": [
    "- 'Size of Home' is wrongly specified to be 'object' type.\n",
    "- Need to be changed to 'numeric' type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30BPH3pRVwlh"
   },
   "source": [
    "#### Fixing 'Size of Home'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V0DMbrZ7ydvh",
    "outputId": "beefaea1-174f-4025-96ab-488a81727182"
   },
   "outputs": [],
   "source": [
    "## printing unique values to understand values to fix\n",
    "print(df['Size Of Home'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0l5NllY0VXz"
   },
   "outputs": [],
   "source": [
    "df['Size Of Home'] = df['Size Of Home'].str.replace(',', '') ## replacing ',' with empty field\n",
    "df['Size Of Home'] = df['Size Of Home'].str.strip('Report SF less than ') ## stripping string value \n",
    "df['Size Of Home'] = df['Size Of Home'].str.strip('more than ') ## again stripping string value\n",
    "df['Size Of Home'] = df['Size Of Home'].astype(np.number) ## changing the dtype by using astype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KT7sKWH0foL",
    "outputId": "8d86c629-ba75-42ed-8868-66a007951511"
   },
   "outputs": [],
   "source": [
    "## printing DataFrame information to see if the correction has been made successfully\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhSAvvr35Ipk"
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ue9dLxKC6Bxp"
   },
   "source": [
    "#### Extracting only year from 'Project Completion Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o46S2iTm6Lmf",
    "outputId": "c32182f3-8a0f-475f-8f7c-72eea51982ec"
   },
   "outputs": [],
   "source": [
    "## printing unique values to understand what values to strip\n",
    "print(df['Project Completion Date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbHVVkon6OoR",
    "outputId": "16a1a14f-2a53-42e8-d5a4-193975035008"
   },
   "outputs": [],
   "source": [
    "df['Project Completion Year'] = df['Project Completion Date'] ## creating a new variable based on 'Project Completion Year' from  'Project Completion Date'\n",
    "df['Project Completion Year'] = df['Project Completion Year'].str[6:] ## stripping values till we get only the year\n",
    "print(df['Project Completion Year'].unique()) ## checking unique values again to see if stripping is successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkq_rmHJOz1G"
   },
   "source": [
    "#### Extracting only Month from 'Project Completion Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oUXKpDJtOxFT",
    "outputId": "172e05fd-dd79-4160-9139-00c5c35378d6"
   },
   "outputs": [],
   "source": [
    "df['Billing Month'] = df['Project Completion Date'] ## creating a new variable based on the billing cycle from  'Project Completion Date'\n",
    "df['Billing Month'] = df['Billing Month'].str[:2] ## stripping values till we get only the month\n",
    "df['Billing Month'].replace({'01':'January','02':'February','03':'March',\n",
    "                                 '04':'April','05':'May','06':'June','07':'July',\n",
    "                                 '08':'August','09':'September','10':'October',\n",
    "                                 '11':'November','12':'December'},inplace=True) ## Assigning month names\n",
    "print(df['Billing Month'].unique()) ## checking unique values again to see if stripping is successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCBui2MCho5a"
   },
   "source": [
    "#### Extracting 'Latitude' and 'Longitude' from 'Location 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNbGZHQzh04F"
   },
   "outputs": [],
   "source": [
    "df['Location 1'] = df['Location 1'].str.split('(').str[1] ## stripping till '(' caharacter\n",
    "df['Location 1'] = df['Location 1'].str.split(')').str[0] ## stripping the ')' character\n",
    "df[['Latitude', 'Longitude']] = df['Location 1'].str.split(',', 1, expand=True) ## dividing 'Location 1' to 'Latitude' and 'Longitude' columns\n",
    "df['Latitude'] = df['Latitude'].astype(np.number) ## fixing dType of 'Latitude' variable\n",
    "df['Longitude'] = df['Longitude'].astype(np.number) ## fixing dType of 'Longitude' variable\n",
    "df.drop('Location 1',axis=1,inplace=True) ## removing the unnecessary 'Location 1' variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lMtRf59QKAX"
   },
   "source": [
    "#### Creating new feature from 'Project County'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNc5WlvfQKAZ",
    "outputId": "332616c9-f440-4f60-9f4c-ee58275e4bfe"
   },
   "outputs": [],
   "source": [
    "## Checking unique county names\n",
    "print(df['Project County'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jafuDv99QKAc"
   },
   "outputs": [],
   "source": [
    "## Creating new column 'Region' from 'Project County' and replacing unique counties with region names\n",
    "df['Region'] = df['Project County']\n",
    "\n",
    "## Central Region\n",
    "df['Region'] = df['Region'].replace(['Oneida','Onondaga','Tioga','Cortland',\n",
    "                                             'Chenango','Broome','Seneca',\n",
    "                                             'Chemung','Madison','Otsego','Cayuga',\n",
    "                                             'Tompkins','Schuyler'],'Central')\n",
    "## East Region\n",
    "df['Region'] = df['Region'].replace(['Albany','Rensselaer','Delaware','Columbia','Ulster',\n",
    "                                             'Dutchess','Washington','Sullivan','Fulton','Schenectady',\n",
    "                                             'Saratoga','Greene','Montgomery','Schoharie'],'East')\n",
    "## West Region\n",
    "df['Region'] = df['Region'].replace(['Niagara','Orleans','Steuben','Wyoming','Livingston',\n",
    "                                             'Wayne','Chautauqua','Erie','Monroe','Allegany',\n",
    "                                             'Genesee','Cattaraugus','Ontario','Yates'],'West')\n",
    "## North Region\n",
    "df['Region'] = df['Region'].replace(['Essex','Lewis','Oswego','Herkimer','Jefferson',\n",
    "                                             'St. Lawrence','Clinton','Franklin','Warren',\n",
    "                                             'Hamilton'],'North')\n",
    "## South Region\n",
    "df['Region'] = df['Region'].replace(['Suffolk','Kings','Bronx','New York','Nassau',\n",
    "                                             'Queens','Orange','Putnam','Rockland','Westchester',\n",
    "                                             'Richmond'],'South')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFP0thcVRSsr"
   },
   "source": [
    "#### New Variable based 'Type of Home Size' on 'Size of Home'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bS6VZmnRSWQ",
    "outputId": "2e9c9bea-cfea-4c8d-fbdf-0727acb6898c"
   },
   "outputs": [],
   "source": [
    "## checking descriptive statistics for size of home\n",
    "df['Size Of Home'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3JviEwjRl5d"
   },
   "outputs": [],
   "source": [
    "## making a new variable 'Size of Residence' from 'Size of Home'\n",
    "df['Type of Home Size'] = df['Size Of Home']\n",
    "## label encoding 'Size of Residence' based on 'Large', 'Medium' and 'Small'\n",
    "df['Type of Home Size'] = ['Large' if x>1803 \n",
    "                           else 'Medium' if 1803>=x>1064 \n",
    "                           else 'Small' \n",
    "                           for x in df['Type of Home Size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aKhRzUQEZTID",
    "outputId": "4f5014b4-4662-4a96-f888-a1b8b8b84f63"
   },
   "outputs": [],
   "source": [
    "## checking value counts of Type of Home Size\n",
    "df['Type of Home Size'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCzBkEVl7mq4"
   },
   "source": [
    "#### Removing Unnecessary Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHcQpqOA6f3d"
   },
   "outputs": [],
   "source": [
    "## 'Reporting Period', 'Project ID' and 'Project ZIP' are not needed for further analysis\n",
    "df.drop(['Reporting Period','Project ID','Project ZIP'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alqFcund7_Ux"
   },
   "source": [
    "#### Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822
    },
    "id": "bz8lISIN7P3L",
    "outputId": "ddde79b2-d429-45dc-b27e-e6bf4bd38e75"
   },
   "outputs": [],
   "source": [
    "## showing cleaned DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_fjtcVs8Dd0",
    "outputId": "263652e1-ef0d-4187-954d-33b2b6eaae4f"
   },
   "outputs": [],
   "source": [
    "## printing information of cleaned DataFrame\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = copy.deepcopy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88jkpH5QAiFa"
   },
   "source": [
    "## Data Preprocessing (Part-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rnfWRaY84N2",
    "outputId": "d2d7eefe-b941-487f-9025-bda9fc0ebbb9"
   },
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include='object').columns ## selecting categorical columns into a list\n",
    "cat_cols1 = df1.select_dtypes(include='object').columns\n",
    "num_cols = df.select_dtypes(include=np.number).columns ## selecting numeric columns into a list\n",
    "num_cols1 = df1.select_dtypes(include=np.number).columns\n",
    "\n",
    "cat_dat = df.select_dtypes(include='object') ## selecting categorical columns into a dataset\n",
    "cat_dat1 = df1.select_dtypes(include='object')\n",
    "num_dat = df.select_dtypes(include=np.number) ## selecting numeric columns into a dataset\n",
    "num_dat1 = df1.select_dtypes(include=np.number)\n",
    "\n",
    "print('Categorical:',cat_cols) ## printing categorical column names\n",
    "print('\\n') ## for spacing\n",
    "print('Numerical:',num_cols) ## printing numerical column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfO7eYejMT5h"
   },
   "source": [
    "### Outlier Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 1: Outliers not removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DZBnc2k0LVC2",
    "outputId": "7ac9f9a3-32f7-4ea1-d5a2-1e0dd33ba4d2"
   },
   "outputs": [],
   "source": [
    "## checking for outliers and extreme values\n",
    "for i in df.select_dtypes(np.number):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.boxplot(df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etkYSupVMeEx"
   },
   "source": [
    "- Outliers shouldn't be removed as the dataset will introduce bias towards projects.\n",
    "- We will further transform it to make the distributions more Gaussian-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLsDZD6YSZDd",
    "outputId": "d38a2252-e747-417b-e500-3536388e75f5"
   },
   "outputs": [],
   "source": [
    "# calculate interquartile range \n",
    "\n",
    "# compute the first quartile using quantile(0.25)\n",
    "# use .drop() to drop the target variable \n",
    "# axis=1: specifies that the labels are dropped from the columns\n",
    "Q1 = num_dat.drop(['First Year Modeled Project Energy Savings $ Estimate',\n",
    "                   'Estimated Annual MMBtu Savings','Estimated Annual kWh Savings',\n",
    "                   'Number Of Units','Longitude','Latitude'], axis=1).quantile(0.25)\n",
    "\n",
    "# compute the first quartile using quantile(0.75)\n",
    "# use .drop() to drop the target variable \n",
    "# axis=1: specifies that the labels are dropped from the columns\n",
    "Q3 = num_dat.drop(['First Year Modeled Project Energy Savings $ Estimate',\n",
    "                   'Estimated Annual MMBtu Savings','Estimated Annual kWh Savings',\n",
    "                   'Number Of Units','Longitude','Latitude'], axis=1).quantile(0.75)\n",
    "\n",
    "# calculate of interquartile range \n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# filter out the outlier values\n",
    "# ~ : selects all rows which do not satisfy the condition\n",
    "# |: bitwise operator OR in python\n",
    "# any() : returns whether any element is True over the columns\n",
    "# axis : \"1\" indicates columns should be altered (use \"0\" for 'index')\n",
    "df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6DJKktMnUhJr",
    "outputId": "6945da9c-b857-4751-b936-1ef2fdb209ea"
   },
   "outputs": [],
   "source": [
    "for i in df.select_dtypes(np.number):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.boxplot(df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wT6vCIkUi_E",
    "outputId": "bd662115-816f-470b-e0ab-46bbb8a39cb2"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2: Outliers Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate interquartile range \n",
    "\n",
    "# compute the first quartile using quantile(0.25)\n",
    "# use .drop() to drop the target variable \n",
    "# axis=1: specifies that the labels are dropped from the columns\n",
    "Q11 = num_dat1.drop(['Longitude','Latitude'], axis=1).quantile(0.25)\n",
    "\n",
    "# compute the first quartile using quantile(0.75)\n",
    "# use .drop() to drop the target variable \n",
    "# axis=1: specifies that the labels are dropped from the columns\n",
    "Q31 = num_dat1.drop(['Longitude','Latitude'], axis=1).quantile(0.75)\n",
    "\n",
    "# calculate of interquartile range \n",
    "IQR1 = Q31 - Q11\n",
    "\n",
    "# filter out the outlier values\n",
    "# ~ : selects all rows which do not satisfy the condition\n",
    "# |: bitwise operator OR in python\n",
    "# any() : returns whether any element is True over the columns\n",
    "# axis : \"1\" indicates columns should be altered (use \"0\" for 'index')\n",
    "df1 = df1[~((df1 < (Q1 - 1.5 * IQR1)) | (df1 > (Q31 + 1.5 * IQR1))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df1.select_dtypes(np.number):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.boxplot(df1[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XI81Xofh8Zbv"
   },
   "source": [
    "### Transformation of Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sqrt Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqr$'] = np.sqrt(df['First Year Modeled Project Energy Savings $ Estimate'])\n",
    "df1['sqr$1'] = np.sqrt(df1['First Year Modeled Project Energy Savings $ Estimate'])\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,6))\n",
    "sns.distplot(df['sqr$'],ax=ax1)\n",
    "sns.distplot(df1['sqr$1'],ax=ax2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrIp_syQMrNr"
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler() ## assigning StandardScaler\n",
    "\n",
    "num_t = ss.fit_transform(df.select_dtypes(np.number)) ## transforming numerical dataset with StandardScaler\n",
    "num_t_dat = pd.DataFrame(data=num_t,columns=df.select_dtypes(np.number).columns) ## creating new encoded DataFrame\n",
    "\n",
    "num_t1 = ss.fit_transform(df1.select_dtypes(np.number)) ## transforming numerical dataset with StandardScaler\n",
    "num_t_dat1 = pd.DataFrame(data=num_t1,columns=df1.select_dtypes(np.number).columns) ## creating new encoded DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1S4UrEFVYKI0",
    "outputId": "f8ba4801-5488-436b-b43e-b3c055c223f2"
   },
   "outputs": [],
   "source": [
    "## checking transformed numerical dataset information\n",
    "print(num_t_dat.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unnU0cnR9c4A"
   },
   "source": [
    "### Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTVTZZUsXHWz",
    "outputId": "3cde15ba-a661-406a-f62c-f45c8e46782e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## categorical dataset information to check for significant variables\n",
    "print(cat_dat.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlxbhWyRQMEn"
   },
   "outputs": [],
   "source": [
    "## removing unnecesary variables\n",
    "cat_dat_dum = cat_dat.drop(['Project Completion Date','Project City','Project County'],axis=1)\n",
    "num_t_dat = num_t_dat.drop(['Latitude','Longitude'],axis=1)\n",
    "\n",
    "cat_dat_dum1 = cat_dat.drop(['Project Completion Date','Project City','Project County'],axis=1)\n",
    "num_t_dat1 = num_t_dat1.drop(['Latitude','Longitude'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvD8lKQiQMCF",
    "outputId": "4d2d83e2-4703-4c63-9842-a72b420ead46"
   },
   "outputs": [],
   "source": [
    "## creating dummy variables for categorical dataset\n",
    "cat_dat_dumm = pd.get_dummies(cat_dat_dum,drop_first=True) ## one-hot encoding categorical dataset\n",
    "cat_dat_dumm1 = pd.get_dummies(cat_dat_dum1,drop_first=True) ## one-hot encoding categorical dataset\n",
    "\n",
    "print(cat_dat_dumm.shape) ## checking encoded categorical dataset shape\n",
    "print(cat_dat_dumm1.shape) ## checking encoded categorical dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XI41TtxtVhW9",
    "outputId": "dc33fa20-a818-4e7b-b410-d7719da32212"
   },
   "outputs": [],
   "source": [
    "## creating new encoded dataset which will be used for analysis\n",
    "df_en = cat_dat_dumm.join(num_t_dat,how='inner') ## using an inner-join function for creating a fully encoded dataset\n",
    "df_en1 = cat_dat_dumm1.join(num_t_dat1,how='inner') ## using an inner-join function for creating a fully encoded dataset\n",
    "\n",
    "df_noen = cat_dat_dumm.join(df.select_dtypes(np.number),how='inner')\n",
    "df_noen1 = cat_dat_dumm1.join(df1.select_dtypes(np.number),how='inner')\n",
    "df_noen = df_noen.drop(['Longitude','Latitude'],axis=1)\n",
    "df_noen1 = df_noen1.drop(['Longitude','Latitude'],axis=1)\n",
    "\n",
    "print(df_en.shape) ## checking final encoded dataset shape\n",
    "print(df_en1.shape) ## checking final encoded dataset shape\n",
    "print('\\n')\n",
    "print(df_noen.shape) ## checking final encoded dataset shape\n",
    "print(df_noen1.shape) ## checking final encoded dataset shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUwvCB4RA1n7"
   },
   "source": [
    "### Encoded Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "vVaKFAWJA6K2",
    "outputId": "e1746f20-f818-43bb-945f-da89ce016a64"
   },
   "outputs": [],
   "source": [
    "## Showing encoded DataFrame with outliers\n",
    "df_en.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Showing unencoded dataframe with outliers\n",
    "df_noen.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHG4Pur_VW_P"
   },
   "source": [
    "## Pandas Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFZpNLZAVW_R"
   },
   "outputs": [],
   "source": [
    "profile = ProfileReport(df, title='Pandas Profiling Report', explorative=True)\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpuWxxjyMpEi"
   },
   "source": [
    "## Plots\n",
    "\n",
    "**Note:-**\n",
    "- Using 'df' or 'Cleaned' DataFrame for plotting exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xWigYqrKpPt"
   },
   "source": [
    "### Correlation Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxiseJMl-a_C"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDSXi5xtNeKB"
   },
   "source": [
    "### Pair Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAWT1EesNetT"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,50))\n",
    "pp = sns.pairplot(df,hue='Type of Home Size',height=10)\n",
    "pp.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_rS4ixjKvTy"
   },
   "source": [
    "### Location Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDPh8-Ol-a8O"
   },
   "outputs": [],
   "source": [
    "## plot a scatter plot on the world map\n",
    "fig = px.scatter_mapbox(df, lat=\"Latitude\", lon=\"Longitude\", hover_name =df[\"Project City\"],\n",
    "                        hover_data=df[[\"Project County\",\"Electric Utility\",\"Size Of Home\"]],\n",
    "                        color_discrete_sequence=[\"fuchsia\"], zoom=5.7, height=600)\n",
    "\n",
    "## set the layout of the map\n",
    "fig.update_layout(\n",
    "    mapbox_style=\"white-bg\",\n",
    "    mapbox_layers=[\n",
    "        {   \"below\": 'traces',\n",
    "            \"sourcetype\": \"raster\",\n",
    "            \"source\": [\n",
    "                \"https://basemap.nationalmap.gov/arcgis/rest/services/USGSImageryOnly/MapServer/tile/{z}/{y}/{x}\"]\n",
    "        }\n",
    "      ])\n",
    "## set magin width to 0 to avoid margins\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khl1p9yReLvf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.scatterplot(df['Longitude'],df['Latitude'],hue = df['Region'],style = df['Pre-Retrofit Home Heating Fuel Type'])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1),borderaxespad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoHlQpgBK_H8"
   },
   "source": [
    "### Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining function to plot against imortant features vs the target feature\n",
    "\n",
    "def targetbar(f, ax1, ax2, ax3, ax4,x1,x2,x3,x4,dat):\n",
    "    \n",
    "    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(20,15))\n",
    "    \n",
    "    ax1.bar(x=x1,height=x2,data=dat)\n",
    "    ax1.set_title(label = x2+' '+'by'+' '+x1)\n",
    "    ax1.set_xlabel(x1)\n",
    "    ax1.set_ylabel(x2)\n",
    "    ax1.tick_params(axis='x',labelrotation=45)\n",
    "    ax1.grid()\n",
    "    \n",
    "    sns.countplot(x=x1,data=dat,ax=ax2)\n",
    "    ax2.set_title('Count of'+' '+x1)\n",
    "    ax2.tick_params(axis='x',labelrotation=45)\n",
    "    ax2.grid()\n",
    "    \n",
    "    ax3.bar(x=x1,height=x3,data=dat)\n",
    "    ax3.set_title(x3+' '+'by'+' '+x1)\n",
    "    ax3.set_xlabel(x1)\n",
    "    ax3.set_ylabel(x3)\n",
    "    ax3.tick_params(axis='x',labelrotation=45)\n",
    "    ax3.grid()\n",
    "    \n",
    "    ax4.bar(x=x1,height=x4,data=dat)\n",
    "    ax4.set_title(x4+' '+'by'+' '+x1)\n",
    "    ax4.set_xlabel(x1)\n",
    "    ax4.set_ylabel(x4)\n",
    "    ax4.tick_params(axis='x',labelrotation=45)\n",
    "    ax4.grid()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return f, ax1, ax2, ax3, ax4,x1,x2,x3,x4,dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1='Type Of Dwelling'\n",
    "x2='First Year Modeled Project Energy Savings $ Estimate'\n",
    "x3='Estimated Annual MMBtu Savings'\n",
    "x4='Estimated Annual kWh Savings'\n",
    "x5='Total Project Cost'\n",
    "dat=df\n",
    "\n",
    "f, ax = plt.subplots(3, 2,figsize=(20,25))\n",
    "    \n",
    "ax[0][0].bar(x=x1,height=x2,data=dat)\n",
    "ax[0][0].set_title(label = x2+' '+'by'+' '+x1)\n",
    "ax[0][0].set_xlabel(x1)\n",
    "ax[0][0].set_ylabel(x2)\n",
    "ax[0][0].tick_params(axis='x',labelrotation=45)\n",
    "ax[0][0].grid()\n",
    "    \n",
    "sns.countplot(x=x1,data=dat,ax=ax[0][1])\n",
    "ax[0][1].set_title('Count of'+' '+x1)\n",
    "ax[0][1].tick_params(axis='x',labelrotation=45)\n",
    "ax[0][1].grid()\n",
    "    \n",
    "ax[1][0].bar(x=x1,height=x3,data=dat)\n",
    "ax[1][0].set_title(x3+' '+'by'+' '+x1)\n",
    "ax[1][0].set_xlabel(x1)\n",
    "ax[1][0].set_ylabel(x3)\n",
    "ax[1][0].tick_params(axis='x',labelrotation=45)\n",
    "ax[1][0].grid()\n",
    "    \n",
    "ax[1][1].bar(x=x1,height=x4,data=dat)\n",
    "ax[1][1].set_title(x4+' '+'by'+' '+x1)\n",
    "ax[1][1].set_xlabel(x1)\n",
    "ax[1][1].set_ylabel(x4)\n",
    "ax[1][1].tick_params(axis='x',labelrotation=45)\n",
    "ax[1][1].grid()\n",
    "\n",
    "ax[2][0].bar(x=x1,height=x5,data=dat)\n",
    "ax[2][0].set_title(x5+' '+'by'+' '+x1)\n",
    "ax[2][0].set_xlabel(x1)\n",
    "ax[2][0].set_ylabel(x5)\n",
    "ax[2][0].tick_params(axis='x',labelrotation=45)\n",
    "ax[2][0].grid()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1='Job Type'\n",
    "x2='First Year Modeled Project Energy Savings $ Estimate'\n",
    "x3='Estimated Annual MMBtu Savings'\n",
    "x4='Estimated Annual kWh Savings'\n",
    "x5='Total Project Cost'\n",
    "dat=df\n",
    "\n",
    "f, ax = plt.subplots(3, 2,figsize=(20,25))\n",
    "    \n",
    "ax[0][0].bar(x=x1,height=x2,data=dat)\n",
    "ax[0][0].set_title(label = x2+' '+'by'+' '+x1)\n",
    "ax[0][0].set_xlabel(x1)\n",
    "ax[0][0].set_ylabel(x2)\n",
    "ax[0][0].tick_params(axis='x',labelrotation=45)\n",
    "ax[0][0].grid()\n",
    "    \n",
    "sns.countplot(x=x1,data=dat,ax=ax[0][1])\n",
    "ax[0][1].set_title('Count of'+' '+x1)\n",
    "ax[0][1].tick_params(axis='x',labelrotation=45)\n",
    "ax[0][1].grid()\n",
    "    \n",
    "ax[1][0].bar(x=x1,height=x3,data=dat)\n",
    "ax[1][0].set_title(x3+' '+'by'+' '+x1)\n",
    "ax[1][0].set_xlabel(x1)\n",
    "ax[1][0].set_ylabel(x3)\n",
    "ax[1][0].tick_params(axis='x',labelrotation=45)\n",
    "ax[1][0].grid()\n",
    "    \n",
    "ax[1][1].bar(x=x1,height=x4,data=dat)\n",
    "ax[1][1].set_title(x4+' '+'by'+' '+x1)\n",
    "ax[1][1].set_xlabel(x1)\n",
    "ax[1][1].set_ylabel(x4)\n",
    "ax[1][1].tick_params(axis='x',labelrotation=45)\n",
    "ax[1][1].grid()\n",
    "\n",
    "ax[2][0].bar(x=x1,height=x5,data=dat)\n",
    "ax[2][0].set_title(x5+' '+'by'+' '+x1)\n",
    "ax[2][0].set_xlabel(x1)\n",
    "ax[2][0].set_ylabel(x5)\n",
    "ax[2][0].tick_params(axis='x',labelrotation=45)\n",
    "ax[2][0].grid()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1='Pre-Retrofit Home Heating Fuel Type'\n",
    "x2='First Year Modeled Project Energy Savings $ Estimate'\n",
    "x3='Estimated Annual MMBtu Savings'\n",
    "x4='Estimated Annual kWh Savings'\n",
    "x5='Total Project Cost'\n",
    "dat=df\n",
    "\n",
    "f, ax = plt.subplots(3, 2,figsize=(20,25))\n",
    "    \n",
    "ax[0][0].bar(x=x1,height=x2,data=dat)\n",
    "ax[0][0].set_title(label = x2+' '+'by'+' '+x1)\n",
    "ax[0][0].set_xlabel(x1)\n",
    "ax[0][0].set_ylabel(x2)\n",
    "ax[0][0].tick_params(axis='x',labelrotation=45)\n",
    "ax[0][0].grid()\n",
    "    \n",
    "sns.countplot(x=x1,data=dat,ax=ax[0][1])\n",
    "ax[0][1].set_title('Count of'+' '+x1)\n",
    "ax[0][1].tick_params(axis='x',labelrotation=45)\n",
    "ax[0][1].grid()\n",
    "    \n",
    "ax[1][0].bar(x=x1,height=x3,data=dat)\n",
    "ax[1][0].set_title(x3+' '+'by'+' '+x1)\n",
    "ax[1][0].set_xlabel(x1)\n",
    "ax[1][0].set_ylabel(x3)\n",
    "ax[1][0].tick_params(axis='x',labelrotation=45)\n",
    "ax[1][0].grid()\n",
    "    \n",
    "ax[1][1].bar(x=x1,height=x4,data=dat)\n",
    "ax[1][1].set_title(x4+' '+'by'+' '+x1)\n",
    "ax[1][1].set_xlabel(x1)\n",
    "ax[1][1].set_ylabel(x4)\n",
    "ax[1][1].tick_params(axis='x',labelrotation=45)\n",
    "ax[1][1].grid()\n",
    "\n",
    "ax[2][0].bar(x=x1,height=x5,data=dat)\n",
    "ax[2][0].set_title(x5+' '+'by'+' '+x1)\n",
    "ax[2][0].set_xlabel(x1)\n",
    "ax[2][0].set_ylabel(x5)\n",
    "ax[2][0].tick_params(axis='x',labelrotation=45)\n",
    "ax[2][0].grid()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=\"Electric Utility\"\n",
    "x2='First Year Modeled Project Energy Savings $ Estimate'\n",
    "x3='Estimated Annual MMBtu Savings'\n",
    "x4='Estimated Annual kWh Savings'\n",
    "x5='Total Project Cost'\n",
    "dat=df\n",
    "\n",
    "f, ax = plt.subplots(3, 2,figsize=(20,25))\n",
    "    \n",
    "ax[0][0].bar(x=x1,height=x2,data=dat)\n",
    "ax[0][0].set_title(label = x2+' '+'by'+' '+x1)\n",
    "ax[0][0].set_xlabel(x1)\n",
    "ax[0][0].set_ylabel(x2)\n",
    "ax[0][0].tick_params(axis='x',labelrotation=45)\n",
    "ax[0][0].grid()\n",
    "    \n",
    "sns.countplot(x=x1,data=dat,ax=ax[0][1])\n",
    "ax[0][1].set_title('Count of'+' '+x1)\n",
    "ax[0][1].tick_params(axis='x',labelrotation=45)\n",
    "ax[0][1].grid()\n",
    "    \n",
    "ax[1][0].bar(x=x1,height=x3,data=dat)\n",
    "ax[1][0].set_title(x3+' '+'by'+' '+x1)\n",
    "ax[1][0].set_xlabel(x1)\n",
    "ax[1][0].set_ylabel(x3)\n",
    "ax[1][0].tick_params(axis='x',labelrotation=45)\n",
    "ax[1][0].grid()\n",
    "    \n",
    "ax[1][1].bar(x=x1,height=x4,data=dat)\n",
    "ax[1][1].set_title(x4+' '+'by'+' '+x1)\n",
    "ax[1][1].set_xlabel(x1)\n",
    "ax[1][1].set_ylabel(x4)\n",
    "ax[1][1].tick_params(axis='x',labelrotation=45)\n",
    "ax[1][1].grid()\n",
    "\n",
    "ax[2][0].bar(x=x1,height=x5,data=dat)\n",
    "ax[2][0].set_title(x5+' '+'by'+' '+x1)\n",
    "ax[2][0].set_xlabel(x1)\n",
    "ax[2][0].set_ylabel(x5)\n",
    "ax[2][0].tick_params(axis='x',labelrotation=45)\n",
    "ax[2][0].grid()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToD = df[df['Type Of Dwelling']=='Single Family']\n",
    "dfToD['Type Of Dwelling'].unique()\n",
    "print(dfToD['Job Type'].unique())\n",
    "print(dfToD.shape)\n",
    "print('lossing',df.shape[0]-dfToD.shape[0],'values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfJT = dfToD[dfToD['Job Type']=='Home Performance']\n",
    "print(dfJT['Job Type'].unique())\n",
    "print(dfJT.shape)\n",
    "print('lossing',df.shape[0]-dfJT.shape[0],'values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPRF = dfJT[dfJT['Pre-Retrofit Home Heating Fuel Type']=='Natural Gas']\n",
    "print(dfPRF['Pre-Retrofit Home Heating Fuel Type'].unique())\n",
    "print(dfPRF.shape)\n",
    "print('lossing',df.shape[0]-dfPRF.shape[0],'values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rejected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEU = dfPRF[dfPRF[\"Electric Utility\"]=='National Grid']\n",
    "print(dfEU[\"Electric Utility\"].unique())\n",
    "print(dfEU.shape)\n",
    "print('lossing',df.shape[0]-dfEU.shape[0],'values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEUNG = dfJT[dfJT[\"Electric Utility\"]=='National Grid']\n",
    "print(dfEUNG[\"Electric Utility\"].unique())\n",
    "print(dfEUNG.shape)\n",
    "print('lossing',df.shape[0]-dfEUNG.shape[0],'values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPRF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bar plots and count plot with Respect to Year\n",
    "x1='Project Completion Year'\n",
    "x2='First Year Modeled Project Energy Savings $ Estimate'\n",
    "x3='Estimated Annual MMBtu Savings'\n",
    "x4='Estimated Annual kWh Savings'\n",
    "dat=dfPRF\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(20,15))\n",
    "    \n",
    "ax1.bar(x=x1,height=x2,data=dat)\n",
    "ax1.set_title(label = x2+' '+'by'+' '+x1)\n",
    "ax1.set_xlabel(x1)\n",
    "ax1.set_ylabel(x2)\n",
    "ax1.tick_params(axis='x',labelrotation=45)\n",
    "ax1.grid()\n",
    "    \n",
    "sns.countplot(x=x1,data=dat,ax=ax2)\n",
    "ax2.set_title('Count of'+' '+x1)\n",
    "ax2.tick_params(axis='x',labelrotation=45)\n",
    "ax2.grid()\n",
    "    \n",
    "ax3.bar(x=x1,height=x3,data=dat)\n",
    "ax3.set_title(x3+' '+'by'+' '+x1)\n",
    "ax3.set_xlabel(x1)\n",
    "ax3.set_ylabel(x3)\n",
    "ax3.tick_params(axis='x',labelrotation=45)\n",
    "ax3.grid()\n",
    "    \n",
    "ax4.bar(x=x1,height=x4,data=dat)\n",
    "ax4.set_title(x4+' '+'by'+' '+x1)\n",
    "ax4.set_xlabel(x1)\n",
    "ax4.set_ylabel(x4)\n",
    "ax4.tick_params(axis='x',labelrotation=45)\n",
    "ax4.grid()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bar plots and count plot with respect to Type of Home Size\n",
    "\n",
    "targetbar (f,ax1,ax2,ax3,ax4,'Type of Home Size','First Year Modeled Project Energy Savings $ Estimate',\n",
    "          'Estimated Annual MMBtu Savings','Estimated Annual kWh Savings',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bar plots and count plot with respect to Region\n",
    "\n",
    "targetbar (f,ax1,ax2,ax3,ax4,'Region','First Year Modeled Project Energy Savings $ Estimate',\n",
    "          'Estimated Annual MMBtu Savings','Estimated Annual kWh Savings',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bar plots and count plot with respect to Billing Month\n",
    "targetbar(f,ax1,ax2,ax3,ax4,'Billing Month','First Year Modeled Project Energy Savings $ Estimate',\n",
    "         'Estimated Annual MMBtu Savings','Estimated Annual kWh Savings',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTkz1iiQsAQy"
   },
   "outputs": [],
   "source": [
    "s = df['Region']\n",
    "counts = s.value_counts()\n",
    "percent = s.value_counts(normalize=True)\n",
    "percent100 = s.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "a = pd.DataFrame({'counts': counts, 'per': percent, 'per100': percent100})\n",
    "b = pd.DataFrame (data = (a['per']*100),index=a.index,columns=['per'])\n",
    "\n",
    "f,ax = plt.subplots(figsize=(10,6))\n",
    "ax = sns.barplot(x=a.index,y=round((a['per']*100),2),data=df)\n",
    "ax.set_title('Percentage of Home Participation by Region',fontsize=14)\n",
    "ax.set_ylabel('Percentage %',fontsize=14)\n",
    "ax.set_xlabel('Region',fontsize=14)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.1f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center',\n",
    "                   color='white', \n",
    "                   size=15,\n",
    "                   xytext = (0, -12), \n",
    "                   textcoords = 'offset points')\n",
    "    \n",
    "for p in ax.patches:\n",
    "    ax.annotate(('%'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center',\n",
    "                   color='white', \n",
    "                   size=15,\n",
    "                   xytext = (23, -12), \n",
    "                   textcoords = 'offset points')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ya_kSbhYq5E9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(df['Region'],hue = df['Electric Utility'])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1),borderaxespad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OV_9WY7weU9R"
   },
   "source": [
    "### Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3zvP5qMq4_U"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(df['Electric Utility'],df['Estimated Annual kWh Savings'])\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wl8ir8GpKg2o"
   },
   "source": [
    "# Statistical Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlJaOF_iOAO8"
   },
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "R9m7CU4xN-T3",
    "outputId": "282cc357-4bb0-4d27-ebe5-60de378224c3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(['Latitude','Longitude'],axis=1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1WWWqZZ1dpd"
   },
   "source": [
    "## Checking for Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKjFNw7l41fk"
   },
   "source": [
    "### Distribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6tfNggibstt7",
    "outputId": "a453d864-c9ed-44cd-a06b-19ca727275c8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2,figsize=(12,15))\n",
    "sns.distplot(df['First Year Modeled Project Energy Savings $ Estimate'],hist=True,kde=True,bins=10,ax=ax[0,0])\n",
    "qqplot(df['First Year Modeled Project Energy Savings $ Estimate'], line='s',ax=ax[0,1])\n",
    "sns.distplot(df['Estimated Annual MMBtu Savings'],hist=True,kde=True,bins=10,ax=ax[1,0])\n",
    "qqplot(df['Estimated Annual MMBtu Savings'], line='s',ax=ax[1,1])\n",
    "sns.distplot(df['Estimated Annual kWh Savings'],hist=True,kde=True,bins=10,ax=ax[2,0])\n",
    "qqplot(df['Estimated Annual kWh Savings'], line='s',ax=ax[2,1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "285tydvs4qOg"
   },
   "source": [
    "- Heavily skewed towards right.\n",
    "- Not normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xxa0Nf3gUfwz",
    "outputId": "1e0c29cc-6d64-4ac9-c5ea-074a5fe0e5d3"
   },
   "outputs": [],
   "source": [
    "stat, p = shapiro(df[\"First Year Modeled Project Energy Savings $ Estimate\"])\n",
    "\n",
    "print(stat,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRLUlJSJ49j5"
   },
   "source": [
    "### Shapiro-Wilk Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94AhMzeI5EwX"
   },
   "source": [
    "**The null and alternate hypothesis of Shapiro test are as follows:**\n",
    "\n",
    "H0: The data is normally distributed\n",
    "\n",
    "H1: The data is not normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHJs1Uzfstoh",
    "outputId": "c4b2d29c-15f2-44dc-cb5a-2d9b92891685"
   },
   "outputs": [],
   "source": [
    "# normality test using shapiro()\n",
    "# the test returns the the test statistics and the p-value of the test\n",
    "stat, p = shapiro(df[\"First Year Modeled Project Energy Savings $ Estimate\"])\n",
    "stat1,p1 = shapiro(df[\"Estimated Annual MMBtu Savings\"])\n",
    "stat2,p2 = shapiro(df[\"Estimated Annual kWh Savings\"])\n",
    "\n",
    "# display the conclusion\n",
    "# set the level of significance to 0.05\n",
    "alpha = 0.05\n",
    "\n",
    "# to print the numeric outputs of the Jarque-Bera test upto 3 decimal places\n",
    "# %.3f: returns the a floating point with 3 decimal digit accuracy\n",
    "# the '%' holds the place where the number is to be printed\n",
    "# if the p-value is greater than alpha print we accept alpha \n",
    "# if the p-value is less than alpha print we reject alpha\n",
    "\n",
    "print('Statistics=%.3f, P-Value=%.3f' % (stat, p))\n",
    "if p > alpha:\n",
    "    print('The data for First Year Modeled Project Energy Savings $ Estimate is normally distributed (fail to reject H0)')\n",
    "else:\n",
    "    print('The data for First Year Modeled Project Energy Savings $ Estimate is not normally distributed (reject H0)')\n",
    "print('\\n')\n",
    "print('Statistics=%.3f, P-Value=%.3f' % (stat1, p1))\n",
    "if p1 > alpha:\n",
    "    print('The data for Estimated Annual MMBtu Savings is normally distributed (fail to reject H0)')\n",
    "else:\n",
    "    print('The data is for Estimated Annual MMBtu Savings not normally distributed (reject H0)')\n",
    "print('\\n')\n",
    "print('Statistics=%.3f, P-Value=%.3f' % (stat2, p2))\n",
    "if p2 > alpha:\n",
    "    print('The data for Estimated Annual kWh Savings is normally distributed (fail to reject H0)')\n",
    "else:\n",
    "    print('The data for Estimated Annual kWh Savings is not normally distributed (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YRQHaEosPu6"
   },
   "source": [
    "# Initial Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "miqWGLW6A6PQ",
    "outputId": "b6267cf4-aeea-4994-b71a-49b87a7d2d37"
   },
   "outputs": [],
   "source": [
    "df_modelling=copy.deepcopy(df)\n",
    "df_modelling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "w7BnWf6sA6PR",
    "outputId": "6050e7c5-1f08-4872-db77-c05ad9fb07a1"
   },
   "outputs": [],
   "source": [
    "# remove 'project county','project city','latitude','longitude','type of home size'\n",
    "\n",
    "df_modelling.drop(['Project County','Project City','Latitude','Longitude','Type of Home Size'],axis=1,inplace=True)\n",
    "df_modelling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "bGAaAa5HA6PU",
    "outputId": "32011a46-bfd0-4ff7-db99-7be2b43872a0"
   },
   "outputs": [],
   "source": [
    "X = df_modelling.drop(['First Year Modeled Project Energy Savings $ Estimate'],axis=1)\n",
    "y = df_modelling['First Year Modeled Project Energy Savings $ Estimate']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oplTxEGoA6PU",
    "outputId": "decbb97c-e27b-43ab-cea1-8c04983ae066"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "G__UG9FaA6PU",
    "outputId": "56b2032f-7932-4720-9a91-f4a1662d0628"
   },
   "outputs": [],
   "source": [
    "# dropping 'project completion date' as we have 'project completion year' in place\n",
    "\n",
    "X_train.drop(['Project Completion Date'],axis=1,inplace=True)\n",
    "X_test.drop(['Project Completion Date'],axis=1,inplace=True)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPeNCNMbA6PV",
    "outputId": "ed88368f-9908-46bc-96e4-c7f36f993e01"
   },
   "outputs": [],
   "source": [
    "# reporting period for all the records is 2021.\n",
    "# therefore, reporting_period-project_completion_year is the num_of_yrs_since_completion which makes more sense\n",
    "\n",
    "X_train['num_yrs_since_proj_completion'] = X_train['Project Completion Year'].astype('int64').apply(lambda x: 2021-x)\n",
    "X_train.drop(['Project Completion Year'],axis=1,inplace=True)\n",
    "\n",
    "X_test['num_yrs_since_proj_completion'] = X_test['Project Completion Year'].astype('int64').apply(lambda x: 2021-x)\n",
    "X_test.drop(['Project Completion Year'],axis=1,inplace=True)\n",
    "\n",
    "print(X_train.head())\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfq1kklGA6PV"
   },
   "source": [
    "## Feature Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4RavMNLA6PW"
   },
   "source": [
    "### Feature Set 1: One Hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABcUHq7HA6PW",
    "outputId": "770f0eda-5dfa-4337-d838-3cc807ed8dc3"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "X_train_ohe = copy.deepcopy(X_train)\n",
    "X_test_ohe = copy.deepcopy(X_test)\n",
    "print(X_train_ohe.shape)\n",
    "print(X_test_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "jtYEa8eNA6PW",
    "outputId": "27a254d0-3f92-4ad9-b509-02f631b22742"
   },
   "outputs": [],
   "source": [
    "cat_dat_tr = X_train_ohe.select_dtypes(include='object')\n",
    "cat_dat_te = X_test_ohe.select_dtypes(include='object')\n",
    "\n",
    "cat_dat_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rLrsmneA6PX",
    "outputId": "51d521c1-745b-473d-9ef3-e4c239945e87"
   },
   "outputs": [],
   "source": [
    "train_objs_num = len(X_train)\n",
    "dataset = pd.concat(objs=[cat_dat_tr,cat_dat_te], axis=0)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "X_tr_cat_dat = copy.deepcopy(dataset[:train_objs_num])\n",
    "X_te_cat_dat = copy.deepcopy(dataset[train_objs_num:])\n",
    "\n",
    "print(X_tr_cat_dat.shape)\n",
    "print(X_te_cat_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdyYIJOzA6PX"
   },
   "outputs": [],
   "source": [
    "##### encoding/scaling numerical data\n",
    "X_tr_num_dat = X_train_ohe.select_dtypes(include=np.number)\n",
    "X_te_num_dat = X_test_ohe.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84Vmw5RZA6PX",
    "outputId": "b9a2c53e-4e82-4737-e556-1c1cb3c43e6f"
   },
   "outputs": [],
   "source": [
    "# scaling numerical data  using standard scaler\n",
    "\n",
    "for i in X_tr_num_dat.columns:\n",
    "    ss=StandardScaler()\n",
    "    X_tr_num_dat[i] = ss.fit_transform(X_tr_num_dat[[i]])\n",
    "    X_te_num_dat[i] = ss.transform(X_te_num_dat[[i]])\n",
    "    \n",
    "print(X_tr_num_dat.shape)\n",
    "print(X_te_num_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fND4qI0wA6PY",
    "outputId": "b519cf5f-afe7-41bd-ac5a-0c71af502176"
   },
   "outputs": [],
   "source": [
    "X_train_ohe = X_tr_cat_dat.join(X_tr_num_dat,how='inner') \n",
    "X_test_ohe = X_te_cat_dat.join(X_te_num_dat,how='inner')\n",
    "\n",
    "print(X_train_ohe.shape)\n",
    "X_test_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpgB3_vZA6PY",
    "outputId": "86acdc46-0f57-4307-9c10-038e2adefffe"
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8n55kkKA6PZ"
   },
   "source": [
    "### Feature Set 2: Frequency Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f35pGD_cA6PZ"
   },
   "outputs": [],
   "source": [
    "X_train_freq = copy.deepcopy(X_train)\n",
    "X_test_freq = copy.deepcopy(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "yz9P3k6JA6PZ",
    "outputId": "8401670f-06aa-499b-8587-be6a5907c188"
   },
   "outputs": [],
   "source": [
    "cat_dat_tr = X_train_freq.select_dtypes(include='object')\n",
    "cat_dat_te = X_test_freq.select_dtypes(include='object')\n",
    "\n",
    "cat_dat_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "bqJfmjPMA6PZ",
    "outputId": "b3ab0a9b-1093-4aad-8c4a-6b2399cf7ebd"
   },
   "outputs": [],
   "source": [
    "c=copy.deepcopy(cat_dat_tr)\n",
    "for i in cat_dat_tr.columns:\n",
    "    d = dict(cat_dat_tr[i].value_counts(normalize=True))\n",
    "    print(d)\n",
    "    cat_dat_tr[i]=cat_dat_tr[i].apply(lambda x:d[x])\n",
    "\n",
    "cat_dat_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "WHUlDAtDA6PZ",
    "outputId": "2c266cca-b993-45f3-d152-49183ea72a46"
   },
   "outputs": [],
   "source": [
    "def return_freq(d,x):\n",
    "    try:\n",
    "        return d[x]\n",
    "    except:\n",
    "        return 0\n",
    "for i in cat_dat_te.columns:\n",
    "    d = dict(c[i].value_counts(normalize=True))\n",
    "    print(d)\n",
    "    cat_dat_te[i]=cat_dat_te[i].apply(lambda x:return_freq(d,x))\n",
    "\n",
    "cat_dat_te.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_dSY8JRYA6Pb",
    "outputId": "1e53a7be-5e2e-4d37-d293-3178a6176195"
   },
   "outputs": [],
   "source": [
    "X_train_freq = cat_dat_tr.join(X_tr_num_dat,how='inner') \n",
    "X_test_freq = cat_dat_te.join(X_te_num_dat,how='inner')\n",
    "\n",
    "print(X_train_freq.shape)\n",
    "X_test_freq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTKRRat3A6Pb"
   },
   "source": [
    "## Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldtAUWFYaUl7"
   },
   "source": [
    "### OLS Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qqHG4Ut8YDco"
   },
   "outputs": [],
   "source": [
    "X = df_en.drop('First Year Modeled Project Energy Savings $ Estimate',axis=1)\n",
    "y = df_en['First Year Modeled Project Energy Savings $ Estimate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "I5wAokZzYDZM",
    "outputId": "d45b9684-1c6a-4e78-cca3-3641fbd06ac7"
   },
   "outputs": [],
   "source": [
    "Xc = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y,Xc).fit()\n",
    "\n",
    "# print the summary output\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zxo3EEUaXyK"
   },
   "source": [
    "#### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLYC3D7zYDVl",
    "outputId": "e6d2be1e-9766-457a-e4a2-4edcdab5e641"
   },
   "outputs": [],
   "source": [
    "cols = list(Xc.columns)\n",
    "while len(cols)>1:\n",
    "  X1 = Xc[cols]\n",
    "  model1 = sm.OLS(y,X1).fit()\n",
    "  pvalues = model1.pvalues\n",
    "  pvalues = pvalues.drop('const')\n",
    "  max_p = max(pvalues)\n",
    "  feature_maxp = pvalues.idxmax()\n",
    "  if max_p > 0.05:\n",
    "    cols.remove(feature_maxp)\n",
    "    print(feature_maxp, max_p)\n",
    "  else:\n",
    "    break\n",
    "\n",
    "selected_features = cols\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6FZ3i8TafNw"
   },
   "source": [
    "#### Base OLS Model after Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kvZm71xEYDSB",
    "outputId": "563811a8-5141-4181-e183-f25d742b059c"
   },
   "outputs": [],
   "source": [
    "Xc1 = Xc[selected_features]\n",
    "model1 = sm.OLS(y,Xc1).fit()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOxkjTYcrIRc"
   },
   "outputs": [],
   "source": [
    "residuals = model1.resid\n",
    "y_pred = model1.predict(Xc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4nlAkzgPdYO"
   },
   "source": [
    "### Testing for Assumptions for OLS Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfCBvodQURaq"
   },
   "source": [
    "#### Assumption 1: Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KpxFKyJXURKW",
    "outputId": "3a0eba43-c886-4a5f-9339-ceb9d3b6c8c7"
   },
   "outputs": [],
   "source": [
    "vf = [vif(Xc1.values,i) for i in range(Xc1.shape[1])]\n",
    "vfdf = pd.DataFrame(vf, index= Xc1.columns, columns=['vif'])\n",
    "vfdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHovim51Si6B"
   },
   "source": [
    "#### Assumption 2: Normality of Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "p2jOmTb0Sigw",
    "outputId": "94155f70-571d-43f5-b059-bb753c38692c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "stats.probplot(residuals,plot=plt)\n",
    "plt.subplot(1,2,2)\n",
    "#skewnorm.fit(residuals)\n",
    "sns.distplot(residuals,fit=skewnorm,kde=True,hist=False,label='Skewed Normal')\n",
    "#norm.fit(residuals)\n",
    "#sns.distplot(residuals,fit=norm,kde=True,hist=False,color='red',label='Standard Normal')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLtVGrvzzRkp"
   },
   "source": [
    "##### Jarque Berra Test for checking goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqz0dqjUyDYL",
    "outputId": "bbed1048-76e6-4a19-b679-9f26210b31cb"
   },
   "outputs": [],
   "source": [
    "jarque_bera(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64lii5zjyxB0"
   },
   "source": [
    "~~~\n",
    "H0: Residuals are normally distributed\n",
    "H1: Residuals are not normally distributed\n",
    "~~~\n",
    "- Since P-Value(0.0) is less than significance level, we will reject H0 to conclude that residuals are not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hLfD0cYPjPA"
   },
   "source": [
    "#### Assumption 3: Homoscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "Pf9eKoh8Pjmw",
    "outputId": "5acf8547-e4cd-4914-8d92-1a03c083a8fa"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.regplot(x=y_pred,y=residuals, lowess=True, line_kws={'color':'red'})\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzyv2XafqiGV"
   },
   "source": [
    "##### Goldfeld Quandt Test for checking Homoscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dJfTfPawqfEp",
    "outputId": "65b70cec-936e-4352-ac4e-7d5acb7c885c"
   },
   "outputs": [],
   "source": [
    "test = sms.het_goldfeldquandt(y=residuals,x=Xc1)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSrhmi0aq_91"
   },
   "source": [
    "~~~\n",
    "H0: Variance of residuals is constant across the range of data\n",
    "H1: Variance of residuals is not constant across the range of  data\n",
    "~~~\n",
    "- Since P-Value(2.0360055000948948e-07) is less than significance level, we will reject H0 to conclude that variance of residuals is not constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKxq4KUkO9bS"
   },
   "source": [
    "#### Assumption 4: Auto-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "O3XnnMOarIAi",
    "outputId": "2096bf9f-fcfc-43f4-8056-7aa57dd73220"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "acf = smt.graphics.plot_acf(residuals,lags=30,ax=ax)\n",
    "acf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oh39dVL-Qlfj"
   },
   "source": [
    "#### Assumption 5: Linearity of Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "qxHgRaq0rH8_",
    "outputId": "677aa1ba-9902-4f4f-86c3-0acd691d46ce"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "sns.regplot(x=y_pred,y=y,lowess=True,line_kws={'color':'red'})\n",
    "plt.subplot(2,1,2)\n",
    "sns.regplot(x=y_pred,y=residuals, lowess=True, line_kws={'color':'red'})\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8R_03u3X0G4p",
    "outputId": "3fa195cc-505b-4a4d-e33c-707833d2668d"
   },
   "outputs": [],
   "source": [
    "sm.stats.diagnostic.linear_rainbow(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3P3tuTvk0K83"
   },
   "source": [
    "~~~\n",
    "H0: Fit of model using full sample = Fit of model using a central subset (linear relationship)\n",
    "H1: Fit of model using full sample is worse compared to fit of model using a central subset.\n",
    "~~~\n",
    "- Since P-Value(7.385520188495804e-34) is lower than significance level, we will reject the H0 to conclude that Fit of model using full sample is worse compared to fit of model using a central subset. We need to improve our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBaAWuxrA6Pd"
   },
   "source": [
    "### Model 1: K Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NN8f-h5039_7"
   },
   "source": [
    "#### 1.1: KNN regression with One-Hot Encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxQn7TUPA6Pe",
    "outputId": "af1da205-345b-42a6-ec90-62d6f653cf21"
   },
   "outputs": [],
   "source": [
    "neigh = KNeighborsRegressor()\n",
    "neigh.fit(X_train_ohe,y_train)\n",
    "\n",
    "y_tr_pred = neigh.predict(X_train_ohe)\n",
    "print('train rmse knn regression:',np.sqrt(mean_squared_error(y_train,y_tr_pred)))\n",
    "\n",
    "y_te_pred = neigh.predict(X_test_ohe)\n",
    "print('test rmse knn regression:',np.sqrt(mean_squared_error(y_test,y_te_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDqxJtPMA6Pf",
    "outputId": "44e864a0-55e1-44d3-fbca-fb8196c65ba8"
   },
   "outputs": [],
   "source": [
    "# finding best value of 'n' by manual tuning\n",
    "train_mse=[]\n",
    "test_mse=[]\n",
    "for n in range(20):\n",
    "  n = n+1\n",
    "  model = KNeighborsRegressor(n_neighbors = n)\n",
    "\n",
    "  model.fit(X_train_ohe, y_train)  #fit the model\n",
    "  y_tr_pred=model.predict(X_train_ohe) #make prediction on test set\n",
    "  tr_mse = mean_squared_error(y_train,y_tr_pred) #calculate rmse\n",
    "  train_mse.append(tr_mse)\n",
    "\n",
    "  y_te_pred=model.predict(X_test_ohe) #make prediction on test set\n",
    "  te_mse = mean_squared_error(y_test,y_te_pred)\n",
    "  test_mse.append(te_mse)\n",
    "  print('test RMSE value for n =' , n , 'is:', np.sqrt(te_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "K4WeVHSmA6Pf",
    "outputId": "235b0102-3dab-4b18-aab5-62318ef58d0f"
   },
   "outputs": [],
   "source": [
    "n = [i for i in range(1,21)]\n",
    "plt.plot(n,test_mse,color='g',label='test mse')\n",
    "plt.plot(n,train_mse,color='r',label='train mse')\n",
    "plt.xticks([1,3,5,7,9,11,13,15,17,19])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQvRxxm5A6Pg"
   },
   "source": [
    "- from the manual hyper parameter tuning, knn regressor with neighbours=7 gave the best mean squared error on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qthm33r8dqC-",
    "outputId": "82a0f8e9-a86f-4820-804c-eb05580c9140"
   },
   "outputs": [],
   "source": [
    "# Setup the parameters \n",
    "k_range = list(range(1, 21))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Instantiate the GridSearchCV object: knn_cv\n",
    "knn_cv = GridSearchCV(knn,param_grid,scoring='r2',cv=5,n_jobs=-1)\n",
    "knn_cv.fit(X_train_ohe,y_train)\n",
    "\n",
    "\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(knn_cv.best_params_))\n",
    "print(\"Best score is {}\".format(knn_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hd5SnkX1A6Pg",
    "outputId": "bf0f8c88-4f65-48db-f4b3-96fd08f8c32e"
   },
   "outputs": [],
   "source": [
    "neigh = KNeighborsRegressor(**knn_cv.best_params_) # picking optimal k as 9 from random search\n",
    "neigh.fit(X_train_ohe,y_train)\n",
    "\n",
    "y_tr_pred = neigh.predict(X_train_ohe)\n",
    "print('train rmse knn regression with best parameters:',np.sqrt(mean_squared_error(y_train,y_tr_pred)))\n",
    "\n",
    "y_te_pred = neigh.predict(X_test_ohe)\n",
    "print('test rmse knn regression with best parameters:',np.sqrt(mean_squared_error(y_test,y_te_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMEsIyNqA6Ph"
   },
   "source": [
    "#### 1.2: KNN regression with Frequency Encoded Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nzU8XKFA6Ph",
    "outputId": "dc7d3360-38e2-41f0-f57e-9cf46b9667f6"
   },
   "outputs": [],
   "source": [
    "neigh = KNeighborsRegressor()\n",
    "neigh.fit(X_train_freq,y_train)\n",
    "\n",
    "y_tr_pred = neigh.predict(X_train_freq)\n",
    "print('train rmse knn regression:',np.sqrt(mean_squared_error(y_train,y_tr_pred)))\n",
    "\n",
    "y_te_pred = neigh.predict(X_test_freq)\n",
    "print('test rmse knn regression:',np.sqrt(mean_squared_error(y_test,y_te_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RB4grLM2A6Ph",
    "outputId": "ebbabcef-cdae-4a43-9e53-b6c65405f1bf"
   },
   "outputs": [],
   "source": [
    "train_mse=[]\n",
    "test_mse=[]\n",
    "for n in range(20):\n",
    "  n = n+1\n",
    "  model = KNeighborsRegressor(n_neighbors = n)\n",
    "\n",
    "  model.fit(X_train_freq, y_train)  #fit the model\n",
    "  y_tr_pred=model.predict(X_train_freq) #make prediction on test set\n",
    "  tr_mse = mean_squared_error(y_train,y_tr_pred) #calculate rmse\n",
    "  train_mse.append(tr_mse)\n",
    "\n",
    "  y_te_pred=model.predict(X_test_freq) #make prediction on test set\n",
    "  te_mse = mean_squared_error(y_test,y_te_pred)\n",
    "  test_mse.append(te_mse)\n",
    "  print('test RMSE value for n =' , n , 'is:', np.sqrt(te_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "ypGuc-7LA6Pi",
    "outputId": "bb490266-b7f1-4755-f390-1ac8d9127d8b"
   },
   "outputs": [],
   "source": [
    "n = [i for i in range(1,21)]\n",
    "plt.plot(n,test_mse,color='g',label='test mse')\n",
    "plt.plot(n,train_mse,color='r',label='train mse')\n",
    "plt.xticks([1,3,5,7,9,11,13,15,17,19])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bibQV8btA6Pi"
   },
   "source": [
    "- n=10 looks optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEItIV9JfwOf",
    "outputId": "76e873a1-f93f-4a73-f779-8ebb293e893e"
   },
   "outputs": [],
   "source": [
    "# Setup the parameters \n",
    "k_range = list(range(1, 21))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Instantiate the GridSearchCV object: knn_cv\n",
    "knn_cv = GridSearchCV(knn,param_grid,scoring='r2',cv=5,n_jobs=-1)\n",
    "knn_cv.fit(X_train_freq,y_train)\n",
    "\n",
    "\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(knn_cv.best_params_))\n",
    "print(\"Best score is {}\".format(knn_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4idwm5vMA6Pj",
    "outputId": "2a7f8e6e-c510-4e79-c2fe-7f5a533e45aa"
   },
   "outputs": [],
   "source": [
    "neigh = KNeighborsRegressor(**knn_cv.best_params_) # fitting with optimal 'n' picked\n",
    "neigh.fit(X_train_freq,y_train)\n",
    "\n",
    "y_tr_pred = neigh.predict(X_train_freq)\n",
    "print('train rmse knn regression with best parameters:',np.sqrt(mean_squared_error(y_train,y_tr_pred)))\n",
    "\n",
    "y_te_pred = neigh.predict(X_test_freq)\n",
    "print('test rmse knn regression with best parameters:',np.sqrt(mean_squared_error(y_test,y_te_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Y9sQZU3A6Pj"
   },
   "source": [
    "- From the  train and test root_mean_squared_error values of base model and knn regression, it is evident that knn regressor showed a significant improvement over the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6_YFAe8A6Pj"
   },
   "source": [
    "### Model 2: Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfaLxYEpA6Pk"
   },
   "source": [
    "#### 2.1: DT regression with One-Hot Encoded Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kw1kony7A6Pk",
    "outputId": "b78139ac-5870-4048-ac11-08ef0cd8828c"
   },
   "outputs": [],
   "source": [
    "dtreg = DecisionTreeRegressor(random_state=42) \n",
    "dtreg.fit(X_train_ohe,y_train) # fitting regressor with ohe encoded features\n",
    "\n",
    "y_tr_pred = dtreg.predict(X_train_ohe)\n",
    "tr_mse = mean_squared_error(y_train,y_tr_pred)\n",
    "y_te_pred = dtreg.predict(X_test_ohe)\n",
    "te_mse = mean_squared_error(y_test,y_te_pred)\n",
    "\n",
    "print('train rmse decision tree regressor:',np.sqrt(tr_mse))\n",
    "print('test rmse decision tree regressor:',np.sqrt(te_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBkPY3tnA6Pl",
    "outputId": "efb94f0e-1b78-4864-fe18-29c581b0659d"
   },
   "outputs": [],
   "source": [
    "# Setup the parameters \n",
    "param_dist = {\"max_depth\": [3,4,5,6,7,8,9,10,11,15,19,20,None],\n",
    "              \"max_features\": [5,7,9,10,14,15,19,20,22,25,27],\n",
    "              \"min_samples_split\": [5,10,20,40,80,100,120,140],\n",
    "              \"min_samples_leaf\": [10,20,40,50,60,70,80,90]\n",
    "              }\n",
    "\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "# Instantiate the GridSearchCV object: tree_cv\n",
    "tree_cv = GridSearchCV(tree,param_dist,scoring='r2',cv=5,n_jobs=-1)\n",
    "tree_cv.fit(X_train_ohe,y_train)\n",
    "\n",
    "\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQe2iryOA6Pl",
    "outputId": "b2c20e92-9fb2-44d7-9ce8-90c43d8f3882"
   },
   "outputs": [],
   "source": [
    "dtreg = DecisionTreeRegressor(**tree_cv.best_params_) # fitting with optimal parameter values\n",
    "dtreg.fit(X_train_ohe,y_train)\n",
    "\n",
    "y_tr_pred = dtreg.predict(X_train_ohe)\n",
    "tr_mse = mean_squared_error(y_train,y_tr_pred)\n",
    "y_te_pred = dtreg.predict(X_test_ohe)\n",
    "te_mse = mean_squared_error(y_test,y_te_pred)\n",
    "\n",
    "print('train rmse decision tree regressor with best parameters:',np.sqrt(tr_mse))\n",
    "print('test rmse decision tree regressor with best parameters:',np.sqrt(te_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ktaT4c4A6Pl"
   },
   "source": [
    "#### 2.2: DT regression with Frequency Encoded Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ks8ohKYA6Pm",
    "outputId": "76d2a81a-f45b-4eb4-f354-c310ec0d95bc"
   },
   "outputs": [],
   "source": [
    "dtreg = DecisionTreeRegressor(random_state=42)\n",
    "dtreg.fit(X_train_freq,y_train) # fitting with frequency encoded features\n",
    "\n",
    "y_tr_pred = dtreg.predict(X_train_freq)\n",
    "tr_mse = mean_squared_error(y_train,y_tr_pred)\n",
    "y_te_pred = dtreg.predict(X_test_freq)\n",
    "te_mse = mean_squared_error(y_test,y_te_pred)\n",
    "\n",
    "print('train rmse decision tree regressor:',np.sqrt(tr_mse))\n",
    "print('test rmse decision tree regressor:',np.sqrt(te_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifQyQtsXA6Pm",
    "outputId": "6385080f-2199-476b-a370-1aaabe0e1f9d"
   },
   "outputs": [],
   "source": [
    "# Setup the parameters \n",
    "param_dist = {\"max_depth\": [3,4,5,6,7,8,9,10,11,15,19,20,None],\n",
    "              \"max_features\": [5,7,9,10,14,15,19,20,22,25,27],\n",
    "              \"min_samples_split\": [5,10,20,40,80,100,120,140],\n",
    "              \"min_samples_leaf\": [10,20,40,50,60,70,80,90]\n",
    "              }\n",
    "\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "\n",
    "tree_cv = GridSearchCV(tree,param_dist,scoring='r2',cv=5,n_jobs=-1)\n",
    "tree_cv.fit(X_train_freq,y_train)\n",
    "\n",
    "\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvZQ5uZRA6Pn",
    "outputId": "7e9a98c4-a9e8-4378-9c15-9aa8e7ed5d78"
   },
   "outputs": [],
   "source": [
    "dtreg = DecisionTreeRegressor(**tree_cv.best_params_) # fitting with optimal values\n",
    "dtreg.fit(X_train_freq,y_train)\n",
    "\n",
    "y_tr_pred = dtreg.predict(X_train_freq)\n",
    "tr_mse = mean_squared_error(y_train,y_tr_pred)\n",
    "y_te_pred = dtreg.predict(X_test_freq)\n",
    "te_mse = mean_squared_error(y_test,y_te_pred)\n",
    "\n",
    "print('train rmse decision tree regressor with best parameters:',np.sqrt(tr_mse))\n",
    "print('test rmse decision tree regressor with best parameters:',np.sqrt(te_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse, test_mse = [],[]\n",
    "\n",
    "# evaluate a decision tree for each depth\n",
    "for n in range(20):\n",
    "    n = n+1\n",
    "    #configure the model\n",
    "    dtreg = DecisionTreeRegressor(**tree_cv.best_params_)\n",
    "    \n",
    "    # fit model on the training dataset\n",
    "    dtreg.fit(X_train_freq,y_train)\n",
    "    \n",
    "    # evaluate on the train dataset\n",
    "    y_tr_pred = dtreg.predict(X_train_freq)\n",
    "    tr_mse = mean_squared_error(y_train,y_tr_pred)\n",
    "    train_mse.append(tr_mse)\n",
    "    \n",
    "    # evaluate on the test dataset\n",
    "    y_te_pred = dtreg.predict(X_test_freq)\n",
    "    te_mse = mean_squared_error(y_test,y_te_pred)\n",
    "    test_mse.append(te_mse)\n",
    "    \n",
    "    # summarize progress\n",
    "    print('>%d, train: %.3f, test: %.3f' % (i, tr_mse, te_mse))\n",
    "    \n",
    "#plot of train and test scores vs tree depth\n",
    "n = [i for i in range(1,21)]\n",
    "plt.plot(n,np.sqrt(test_mse),'-o',label='test rmse')\n",
    "plt.plot(n,np.sqrt(train_mse),'-o',label='train rmse')\n",
    "plt.xticks([1,3,5,7,9,11,13,15,17,19])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfLrYBXFA6Pn"
   },
   "source": [
    "- Overall, decision tree regressor showed significant improvement over the base model very much in line with knn regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xgWOtKrA6Pn"
   },
   "source": [
    "## Base Models Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRtJgHOHcTGV"
   },
   "source": [
    "### OLS Base Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoSNkv4vcW1f"
   },
   "source": [
    "**Interpretation:**\n",
    "\n",
    "The R-squared value obtained from this model is 0.761 which means that the above model explains 76.1% of the variation in the First Year Modeled Project Energy Savings $ Estimate.\n",
    "\n",
    "**Durbin-Watson Test:**\n",
    "\n",
    "The test is used to check the autocorrelation between the residuals.\n",
    "\n",
    "- If the Durbin-Watson test statistic is near to 2: no autocorrelation\n",
    "- If the Durbin-Watson test statistic is between 0 and 2: positive autocorrelation\n",
    "- If the Durbin-Watson test statistic is between 2 and 4: negative autocorrelation\n",
    "\n",
    "The summary output shows that the value of the test statistic is close to 2 (= 2.047) which means there is no autocorrelation.\n",
    "\n",
    "**Jarque-Bera Test:**\n",
    "\n",
    "The test is used to check the normality of the residuals. Here, the p-value of the test is less than 0.05; that implies the residuals are not normally distributed.\n",
    "\n",
    "**'Cond. No':**\n",
    "\n",
    "(= 1) represents the Condition Number (CN) which is used to check the multicollinearity.\n",
    "\n",
    "- If CN < 100: no multicollinearity\n",
    "- If CN is between 100 and 1000: moderate multicollinearity\n",
    "- If CN > 1000: severe multicollinearity\n",
    "\n",
    "Thus, it can be seen that there is no multicollinearity in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCZMlJkjcO0j"
   },
   "source": [
    "### ML Base Models Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3tDeHb7A6Pn"
   },
   "source": [
    "| Algorithm | Encoding | Test MSE |\n",
    "| --- | --- | --- |\n",
    "| Base Model | (Irrespective) | 92908 |\n",
    "| KNN Regressor | One hot Encoding | 19398 |\n",
    "| KNN Regressor | Frequency Encoding | 23563 |\n",
    "| Decision Tree Regressor | One hot Encoding | 22840 |\n",
    "| Decision Tree Regressor | Frequency Encoding | 20049 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yYPPc6vA6Po"
   },
   "source": [
    "- KNN regressor with one hot encoding has emerged the best so far with decision tree regressor+ frequency encoding giving the next best Mean Squared Error on test data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Home_Performance_Improvement.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
